# ğŸ¤– AI-Driven Assignment Evaluation & Scoring System

## ğŸ¯ Problem Statement
Innomatics receives multiple student assignment ZIP files daily, each containing several PDF submissions. Manual evaluation consumes a lot of time and leads to inconsistent scoring.

We aim to build a system that:
- Accepts assignment ZIP files
- Extracts PDFs
- Splits text into Q&A
- Evaluates with an AI model
- Generates detailed scoring reports automatically

---

## ğŸš€ Workflow

1ï¸âƒ£ Upload ZIP file of student assignments  
2ï¸âƒ£ Extract PDFs (supports nested folders)  
3ï¸âƒ£ Extract text from each PDF  
4ï¸âƒ£ Split into Question + Answer pairs  
5ï¸âƒ£ LLM evaluates each answer  
6ï¸âƒ£ AI returns **Score (0â€“10)** + **Feedback**  
7ï¸âƒ£ Final report generated as structured JSON  

---

## ğŸ“Œ Sample Output (Report)

**Student:** John Doe  
**Module:** Python Basics

| Q.No | Question | Score | Feedback |
|------|----------|-------|----------|
| 1 | What is a list in Python? | 8/10 | Good explanation but missed examples |
| 2 | Write a loop to print 1 to 5 | 10/10 | Correct logic and output |

**Total Score: 90/100**  
**Overall Feedback:** Very good but add more examples next time.

---

## ğŸŒ Demo

ğŸ”— **Live Demo Link:**  
ğŸ‘‰ *https://youtu.be/0YdWo36fqu8*

---

## ğŸ–¼ System Snapshots

### Dashboard UI
<img width="1920" height="881" alt="AI-Driven Assignment Evaluation and Scoring System Snapshot" src="https://github.com/user-attachments/assets/3f8da83d-2ea1-41cc-bea7-184ba69d6617" />

---

## âœ¨ Key Benefits
- Fully automated evaluation
- Faster & fair scoring
- Useful feedback for improvement
- Easily scalable for batch assignments

---

## ğŸ”® Future Enhancements
- Code execution validation
- Plagiarism check
- Role-based portals for faculty & students
